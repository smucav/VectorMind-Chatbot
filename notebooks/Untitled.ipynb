{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ee227837-09f7-418f-8024-55cf7d919109",
   "metadata": {},
   "source": [
    "# Title and Introduction\n",
    "# Exploratory Data Analysis and Preprocessing for Complaint Analysis\n",
    "\n",
    "This notebook performs exploratory data analysis (EDA) and preprocessing on the Consumer Financial Protection Bureau (CFPB) complaint dataset, as per Task 1 requirements. The goal is to understand the data's structure, content, and quality, and prepare it for the Retrieval-Augmented Generation (RAG) pipeline. The analysis aligns with CrediTrust's business objectives (e.g., reducing trend identification time) and ensures the data is suitable for semantic search and embedding."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab52307d-c2f7-44a7-b366-02e42eb4e8c4",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b36d5a8a-598f-41be-b3d6-33a2ced35278",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import re\n",
    "from pathlib import Path\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf68a074-f36b-4bb0-85ac-4cf4a3420bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths\n",
    "DATA_DIR = Path(\"../data\")\n",
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "dataset_path = \"../data/raw/complaints.csv\"\n",
    "\n",
    "CHUNK_SIZE = 10000 \n",
    "# Initialize variables for chunked analysis\n",
    "total_rows = 0\n",
    "product_counts = pd.Series(dtype=int)\n",
    "missing_narratives = 0\n",
    "narrative_lengths = []\n",
    "chunks = []\n",
    "\n",
    "# Process dataset in chunks\n",
    "for chunk in pd.read_csv(dataset_path, chunksize=CHUNK_SIZE, low_memory=False):\n",
    "    total_rows += len(chunk)\n",
    "    # Count products\n",
    "    chunk_product_counts = chunk['Product'].value_counts()\n",
    "    product_counts = product_counts.add(chunk_product_counts, fill_value=0)\n",
    "    # Count missing narratives\n",
    "    missing_narratives += chunk['Consumer complaint narrative'].isnull().sum()\n",
    "    # Calculate narrative lengths\n",
    "    chunk['narrative_length'] = chunk['Consumer complaint narrative'].apply(\n",
    "        lambda x: len(str(x).split()) if pd.notnull(x) else 0\n",
    "    )\n",
    "    narrative_lengths.extend(chunk['narrative_length'].tolist())\n",
    "    # Store chunk for preprocessing\n",
    "    chunks.append(chunk)\n",
    "\n",
    "print(f\"Loaded dataset with {total_rows} rows in chunks of {CHUNK_SIZE}.\")\n",
    "df_head = chunks[0].head()  # Display first few rows of first chunk\n",
    "df_head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4367f5d0-05f8-41ff-9693-b762effea835",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Business context: Define target products for filtering\n",
    "TARGET_PRODUCTS = [\n",
    "    \"Credit card\",\n",
    "    \"Personal loan\",\n",
    "    \"Buy Now, Pay Later (BNPL)\",\n",
    "    \"Savings account\",\n",
    "    \"Money transfers\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f19427-8c8f-428b-a21f-a916a5cc2360",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataset_path):\n",
    "    \"\"\"Load the CFPB dataset and return a DataFrame.\"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(dataset_path)\n",
    "        print(f\"Loaded dataset with {len(df)} records.\")\n",
    "        return df\n",
    "    except FileNotFoundError:\n",
    "        print(\"Dataset file not found. Please provide the correct path.\")\n",
    "        return None\n",
    "\n",
    "dataset_path = \"../data/raw/complaints.csv\"\n",
    "df = load_data(dataset_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd2ba398-c887-432b-bf75-5213e5bb053e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_complaint_distribution(df):\n",
    "    \"\"\"Analyze and visualize complaint distribution across products.\"\"\"\n",
    "    product_counts = df['Product'].value_counts()\n",
    "    print(\"\\nComplaint Distribution by Product:\")\n",
    "    print(product_counts)\n",
    "    \n",
    "    # Visualize distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.barplot(x=product_counts.values, y=product_counts.index)\n",
    "    plt.title(\"Complaint Distribution by Product\")\n",
    "    plt.xlabel(\"Number of Complaints\")\n",
    "    plt.ylabel(\"Product\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DATA_DIR / \"product_distribution.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return product_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6de5acd5-f1b7-49cf-a0c4-bd430caa43e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_narrative_lengths(df):\n",
    "    \"\"\"Calculate and visualize word counts of consumer complaint narratives.\"\"\"\n",
    "    df['narrative_length'] = df['Consumer complaint narrative'].apply(\n",
    "        lambda x: len(str(x).split()) if pd.notnull(x) else 0\n",
    "    )\n",
    "    \n",
    "    print(\"\\nNarrative Length Statistics:\")\n",
    "    print(df['narrative_length'].describe())\n",
    "    \n",
    "    # Visualize length distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(df['narrative_length'], bins=50, kde=True)\n",
    "    plt.title(\"Distribution of Complaint Narrative Word Counts\")\n",
    "    plt.xlabel(\"Word Count\")\n",
    "    plt.ylabel(\"Frequency\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(DATA_DIR / \"narrative_length_distribution.png\")\n",
    "    plt.close()\n",
    "    \n",
    "    return df['narrative_length'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ddc616-90cd-4c3b-bd96-9a6a51caf09f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_missing_narratives(df):\n",
    "    \"\"\"Identify complaints with and without narratives.\"\"\"\n",
    "    missing_narratives = df[' veritable complaint narrative'].isnull().sum()\n",
    "    non_missing_narratives = len(df) - missing_narratives\n",
    "    print(f\"\\nMissing Narratives: {missing_narratives} ({missing_narratives/len(df)*100:.2f}%)\")\n",
    "    print(f\"Non-Missing Narratives: {non_missing_narratives} ({non_missing_narratives/len(df)*100:.2f}%)\")\n",
    "    \n",
    "    return missing_narratives, non_missing_narratives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b1f10758-88e8-4c42-8baa-14fdb008edfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_narrative(text):\n",
    "    \"\"\"Clean complaint narratives for RAG suitability.\"\"\"\n",
    "    if pd.isnull(text):\n",
    "        return text\n",
    "    # Lowercase\n",
    "    text = text.lower()\n",
    "    # Remove special characters, keep alphanumeric and basic punctuation\n",
    "    text = re.sub(r'[^a-z0-9\\s.,!?]', '', text)\n",
    "    # Remove boilerplate phrases\n",
    "    boilerplate_phrases = [\n",
    "        r\"i am writing to file a complaint\",\n",
    "        r\"please assist me\",\n",
    "        r\"this is regarding my account\"\n",
    "    ]\n",
    "    for phrase in boilerplate_phrases:\n",
    "        text = re.sub(phrase, '', text, flags=re.IGNORECASE)\n",
    "    # Remove excessive whitespace\n",
    "    text = re.sub(r'\\s+', ' ', text).strip()\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f81633c4-86c3-400e-8b67-a62db42e186d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df):\n",
    "    \"\"\"Filter and clean the dataset for the five target products.\"\"\"\n",
    "    # Filter for target products\n",
    "    initial_count = len(df)\n",
    "    df_filtered = df[df['Product'].isin(TARGET_PRODUCTS)].copy()\n",
    "    print(f\"\\nFiltered dataset to {len(df_filtered)} records from {initial_count} for target products.\")\n",
    "    \n",
    "    # Remove empty narratives\n",
    "    non_empty_count = len(df_filtered)\n",
    "    df_filtered = df_filtered[df_filtered['Consumer complaint narrative'].notnull()]\n",
    "    print(f\"Removed {non_empty_count - len(df_filtered)} records with empty narratives.\")\n",
    "    \n",
    "    # Clean narratives\n",
    "    df_filtered['cleaned_narrative'] = df_filtered['Consumer complaint narrative'].apply(clean_narrative)\n",
    "    \n",
    "    # Verify no empty cleaned narratives\n",
    "    empty_cleaned = df_filtered['cleaned_narrative'].isnull().sum()\n",
    "    if empty_cleaned > 0:\n",
    "        print(f\"Warning: {empty_cleaned} cleaned narratives are empty.\")\n",
    "    \n",
    "    return df_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a0e0598-6a03-44b1-8d5d-a969e4bc61f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_cleaned_data(df, output_path):\n",
    "    \"\"\"Save the cleaned and filtered dataset.\"\"\"\n",
    "    df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved cleaned dataset to {output_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0dffcd28-401a-44f4-a940-dd4b7257ff7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset file not found. Please provide the correct path.\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load dataset (replace with actual CFPB dataset path)\n",
    "    dataset_path = \"../data/raw/complaints.csv\"  # Update with actual path\n",
    "    df = load_data(dataset_path)\n",
    "    if df is None:\n",
    "        return\n",
    "    \n",
    "    # Business-focused EDA\n",
    "    print(\"Performing business-focused EDA...\")\n",
    "    product_counts = analyze_complaint_distribution(df)\n",
    "    narrative_stats = analyze_narrative_lengths(df)\n",
    "    missing_narratives, non_missing_narratives = analyze_missing_narratives(df)\n",
    "    \n",
    "    # Preprocess data for RAG\n",
    "    print(\"\\nPreprocessing data for RAG pipeline...\")\n",
    "    df_filtered = preprocess_data(df)\n",
    "    \n",
    "    # Save cleaned dataset\n",
    "    save_cleaned_data(df_filtered, OUTPUT_PATH)\n",
    "    \n",
    "    # Generate EDA summary for report\n",
    "    summary = f\"\"\"\n",
    "### EDA Summary\n",
    "\n",
    "**Business Insights**:\n",
    "The CFPB dataset contains {len(df)} complaints, with {product_counts.sum()} across all products. The distribution of complaints acrossAmenities across the five target products (Credit Card, Personal Loan, BNPL, Savings Account, Money Transfers) is as follows:\n",
    "{', '.join([f'{k}: {v}' for k, v in product_counts.items() if k in TARGET_PRODUCTS])}.\n",
    "This distribution highlights key areas of customer dissatisfaction, particularly for high-volume products like {product_counts.idxmax()} ({product_counts.max()} complaints), which aligns with CrediTrust’s need to quickly identify major complaint trends (KPI 1). For example, a high volume of BNPL complaints could indicate operational issues like billing disputes or fraud, critical for Product Managers like Asha to address proactively.\n",
    "\n",
    "**RAG Suitability**:\n",
    "The narrative length analysis shows a mean word count of {narrative_stats['mean']:.2f} (min: {narrative_stats['min']:.0f}, max: {narrative_stats['max']:.0f}). {f'Many narratives are short (<50 words), which may limit semantic richness for RAG retrieval.' if narrative_stats['mean'] < 50 else 'Most narratives are sufficiently long for effective embedding.'} {missing_narratives} complaints ({missing_narratives/len(df)*100:.2f}%) lack narratives, reducing the dataset’s effective size for RAG. The cleaning process removed boilerplate text and special characters to improve embedding quality, ensuring semantic coherence for the vector store.\n",
    "\n",
    "**Next Steps**:\n",
    "The filtered dataset ({len(df_filtered)} records) is saved to {OUTPUT_PATH}, ready for chunking and embedding in Task 2. The focus on high-volume products like BNPL will guide the creation of test questions for Task 3, ensuring the RAG system addresses key stakeholder needs.\n",
    "\"\"\"\n",
    "    with open(DATA_DIR / \"eda_summary.md\", \"w\") as f:\n",
    "        f.write(summary)\n",
    "    print(f\"EDA summary saved to {DATA_DIR / 'eda_summary.md'}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4e7c76e-a21a-4070-a60c-e351e9263d38",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
